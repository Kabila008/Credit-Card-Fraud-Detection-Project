{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a444b69a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a444b69a",
    "outputId": "f4a90c88-7c03-4c92-f794-561474880bdb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7da6ea",
   "metadata": {
    "id": "5c7da6ea"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_auc_score, average_precision_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "222d736c",
   "metadata": {
    "id": "222d736c"
   },
   "outputs": [],
   "source": [
    "# Load and return a dataset from the given file path.\n",
    "\n",
    "def load_dataset(file_path):\n",
    "\n",
    "    # Load the dataset from the specified file path\n",
    "    dataset = pd.read_csv(file_path)\n",
    "\n",
    "    # The loaded dataset\n",
    "    return dataset\n",
    "\n",
    "# Usage:\n",
    "file_path = '/home/docode/project/my_paypal_creditcard.csv'\n",
    "credit_card_dataset = load_dataset(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd50a347",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd50a347",
    "outputId": "a0101b1e-bd27-41a0-805d-195687ddbb3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 15 rows of dataset:\n",
      "    Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
      "1    0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
      "2    1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
      "3    1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
      "4    2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
      "5    2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728   \n",
      "6    4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708   \n",
      "7    7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118   \n",
      "8    7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818   \n",
      "9    9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761   \n",
      "10  10.0  1.449044 -1.176339  0.913860 -1.375667 -1.971383 -0.629152   \n",
      "11  10.0  0.384978  0.616109 -0.874300 -0.094019  2.924584  3.317027   \n",
      "12  10.0  1.249999 -1.221637  0.383930 -1.234899 -1.485419 -0.753230   \n",
      "13  11.0  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544   \n",
      "14  12.0 -2.791855 -0.327771  1.641750  1.767473 -0.136588  0.807596   \n",
      "\n",
      "          V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
      "0   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
      "1  -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
      "2   0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
      "3   0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
      "4   0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
      "5   0.476201  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427   \n",
      "6  -0.005159  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055   \n",
      "7   1.120631 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709   \n",
      "8   0.370145  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592   \n",
      "9   0.651583  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050   \n",
      "10 -1.423236  0.048456 -1.720408  ... -0.009302  0.313894  0.027740  0.500512   \n",
      "11  0.470455  0.538247 -0.558895  ...  0.049924  0.238422  0.009130  0.996710   \n",
      "12 -0.689405 -0.227487 -2.094011  ... -0.231809 -0.483285  0.084668  0.392831   \n",
      "13 -0.096717  0.115982 -0.221083  ... -0.036876  0.074412 -0.071407  0.104744   \n",
      "14 -0.422911 -1.907107  0.755713  ...  1.151663  0.222182  1.020586  0.028317   \n",
      "\n",
      "         V25       V26       V27       V28  Amount  Class  \n",
      "0   0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1   0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2  -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3   0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
      "5  -0.232794  0.105915  0.253844  0.081080    3.67      0  \n",
      "6   0.750137 -0.257237  0.034507  0.005168    4.99      0  \n",
      "7  -0.415267 -0.051634 -1.206921 -1.085339   40.80      0  \n",
      "8   0.373205 -0.384157  0.011747  0.142404   93.20      0  \n",
      "9  -0.069733  0.094199  0.246219  0.083076    3.68      0  \n",
      "10  0.251367 -0.129478  0.042850  0.016253    7.80      0  \n",
      "11 -0.767315 -0.492208  0.042472 -0.054337    9.99      0  \n",
      "12  0.161135 -0.354990  0.026416  0.042422  121.50      0  \n",
      "13  0.548265  0.104094  0.021491  0.021293   27.50      0  \n",
      "14 -0.232746 -0.235557 -0.164778 -0.030154   58.80      0  \n",
      "\n",
      "[15 rows x 31 columns]\n",
      "Statistical summary:\n",
      "                Time            V1            V2            V3            V4  \\\n",
      "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
      "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
      "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
      "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
      "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
      "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
      "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
      "\n",
      "                 V5            V6            V7            V8            V9  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
      "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
      "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
      "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
      "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
      "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
      "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
      "\n",
      "       ...           V21           V22           V23           V24  \\\n",
      "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
      "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
      "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
      "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
      "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
      "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
      "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
      "\n",
      "                V25           V26           V27           V28         Amount  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
      "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
      "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
      "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
      "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
      "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
      "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
      "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
      "\n",
      "               Class  \n",
      "count  284807.000000  \n",
      "mean        0.001727  \n",
      "std         0.041527  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "Dataset dimension:\n",
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of the first 15 rows,statistical summary,and dataset's dimension.\n",
    "\n",
    "def dataset_summary(data):\n",
    "\n",
    "    # Print first 15 rows of dataset\n",
    "    print(\"First 15 rows of dataset:\")\n",
    "    print(data.head(15))\n",
    "\n",
    "    # Print statistical summary\n",
    "    print(\"Statistical summary:\")\n",
    "    print(data.describe())\n",
    "\n",
    "    # Print dataset dimension\n",
    "    print(\"Dataset dimension:\")\n",
    "    print(data.shape)\n",
    "\n",
    "# Usage:\n",
    "dataset_summary(credit_card_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80f3e8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "a80f3e8b",
    "outputId": "3f5b146d-5767-4b82-9f38-3b67f2ed1b0d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-df2efde3-08ab-4419-8979-f5befa70912e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df2efde3-08ab-4419-8979-f5befa70912e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-df2efde3-08ab-4419-8979-f5befa70912e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-df2efde3-08ab-4419-8979-f5befa70912e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-f777444d-2de9-4176-a83f-de5696e39e0a\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f777444d-2de9-4176-a83f-de5696e39e0a')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-f777444d-2de9-4176-a83f-de5696e39e0a button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with null values from the dataset.\n",
    "\n",
    "def remove_null_values(data):\n",
    "\n",
    "    cleaned_data = data.dropna()\n",
    "    return cleaned_data\n",
    "\n",
    "# Example usage:\n",
    "cleaned_credit_card_data = remove_null_values(credit_card_dataset)\n",
    "cleaned_credit_card_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22dc63db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22dc63db",
    "outputId": "e3a9f412-add2-446f-faf8-de084d6167a2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of null values in cleaned data:\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "Column names from the original dataset: Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the count of null values in the cleaned data and the column names from the original dataset.\n",
    "\n",
    "def summarize_cleaned_data(data, original_columns):\n",
    "\n",
    "    # Print count of null values in the cleaned data\n",
    "    print(\"Count of null values in cleaned data:\")\n",
    "    print(data.isnull().sum())\n",
    "\n",
    "    # Print the column names from the original dataset\n",
    "    print(\"Column names from the original dataset:\", original_columns)\n",
    "\n",
    "# Usage:\n",
    "original_columns = cleaned_credit_card_data.columns\n",
    "summarize_cleaned_data(cleaned_credit_card_data, original_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4481b56d",
   "metadata": {
    "id": "4481b56d"
   },
   "outputs": [],
   "source": [
    "# Create and display histograms for numerical columns in the dataset.\n",
    "\n",
    "def plot_numerical_histograms(data, columns):\n",
    "\n",
    "    # Create subplots for histograms\n",
    "    num_columns = len(columns)\n",
    "    fig, axs = plt.subplots(nrows=num_columns // 3 + 1, ncols=3, figsize=(15, 10))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Loop through numerical columns and plot histograms\n",
    "    for x, col in enumerate(columns):\n",
    "        axs[x].hist(data[col], bins=20)\n",
    "        axs[x].set_title(col)\n",
    "        axs[x].set_xlabel(col)\n",
    "        axs[x].set_ylabel('Count')\n",
    "\n",
    "    # Hide the last subplot (empty)\n",
    "    for x in range(num_columns, len(axs)):\n",
    "        axs[x].axis('off')\n",
    "\n",
    "    # Ensure tight layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# List of numerical columns to plot\n",
    "numerical_columns = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12',\n",
    "                     'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24',\n",
    "                     'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
    "\n",
    "# Usage:\n",
    "#plot_numerical_histograms(cleaned_credit_card_data, numerical_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79da2fac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "79da2fac",
    "outputId": "56121b20-7917-4186-829f-7a5ab2ab51d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Non-Fraudulent Transactions: 284315\n",
      "Count of Fraudulent Transactions: 492\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to plot the distribution of fraudulent and non-fraudulent transactions in the dataset.\n",
    "\n",
    "def plot_class_distribution(data):\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Define custom colors for bars\n",
    "    custom_palette = {0: 'green', 1: 'red'}\n",
    "\n",
    "    # Create a bar plot to visualize the distribution\n",
    "    sns.countplot(data=data, x='Class', palette=custom_palette)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Non-Fraudulent and Fraudulent Transactions')\n",
    "    plt.xticks([0, 1], ['Non-Fraudulent', 'Fraudulent'])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Class column contains the class labels (0 for non-fraudulent, 1 for fraudulent)\n",
    "class_counts = cleaned_credit_card_data['Class'].value_counts()\n",
    "\n",
    "print(\"Count of Non-Fraudulent Transactions:\", class_counts[0])\n",
    "print(\"Count of Fraudulent Transactions:\", class_counts[1])\n",
    "\n",
    "# Call the function with the cleaned_credit_card_data\n",
    "plot_class_distribution(cleaned_credit_card_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c78b7c",
   "metadata": {
    "id": "e1c78b7c"
   },
   "source": [
    "From the histogram presented, it's evident that the dataset suffers from a significant class imbalance. Specifically, it contains 492 instances of fraudulent transactions and a staggering 284,315 instances of non-fraudulent transactions. To rectify this imbalance and enhance the model's performance, one effective approach is to calculate and apply class weights.\n",
    "\n",
    "Class weights serve the purpose of assigning higher weights to the minority class (fraudulent transactions) and lower weights to the majority class (non-fraudulent transactions) during the training process. This strategic allocation of weights aims to mitigate the challenges posed by class imbalance when training machine learning models.\n",
    "\n",
    "The rationale behind employing class weights lies in the model's objective, which is to minimize the overall error rate. Without such weighting, the model may inadvertently prioritize accuracy on the majority class, potentially neglecting the minority class. By introducing appropriate class weights, the influence of each class during training is balanced. This means that the model places more emphasis on the minority class, thereby improving its ability to detect and accurately classify instances belonging to the minority class.\n",
    "\n",
    "In essence, the utilization of class weights represents a valuable technique for enhancing a model's performance, particularly with regard to the detection and classification of instances from the minority (fraudulent) class within an imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f648e",
   "metadata": {
    "id": "ad8f648e"
   },
   "source": [
    "### Computing logistic regression model with balanced class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fcefdb6",
   "metadata": {
    "id": "9fcefdb6"
   },
   "outputs": [],
   "source": [
    "# Function to train a logistic regression model with balanced class weights.\n",
    "\n",
    "def train_logistic_regression_with_balanced_weights(X_train, y_train):\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X = cleaned_credit_card_data.drop('Class', axis=1)\n",
    "    y = cleaned_credit_card_data['Class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Compute balanced class weights\n",
    "    class_weights_balanced = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "    # Create and train a logistic regression model with balanced class weights\n",
    "    balanced_logreg = LogisticRegression(class_weight={0: class_weights_balanced[0], 1: class_weights_balanced[1]})\n",
    "    balanced_logreg.fit(X_train, y_train)\n",
    "\n",
    "    return balanced_logreg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "CMwWxYtfPuIe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "CMwWxYtfPuIe",
    "outputId": "e76c0849-6414-4c64-a1b8-e548ce2e7bca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight={0: 0.5008661206149896, 1: 289.14340101522845})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight={0: 0.5008661206149896, 1: 289.14340101522845})</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight={0: 0.5008661206149896, 1: 289.14340101522845})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into features (X) and target (y)\n",
    "X = cleaned_credit_card_data.drop('Class', axis=1)\n",
    "y = cleaned_credit_card_data['Class']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the logistic regression model with balanced class weights\n",
    "trained_logistic_regression = train_logistic_regression_with_balanced_weights(X_train_scaled, y_train)\n",
    "trained_logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2593b1a6",
   "metadata": {
    "id": "2593b1a6"
   },
   "source": [
    "As observed, when the class weight is less than 1, it signifies that the algorithm will de-emphasize the majority class (labeled as 0). Conversely, when the weight is significantly greater than 1, it reflects the presence of a class imbalance and the intention to assign greater importance to the minority class.\n",
    "\n",
    "By assigning higher weights to instances belonging to the minority class, the model takes a more rigorous stance on misclassifications within this class. This deliberate emphasis on the minority class encourages the model to diligently capture and learn the distinct patterns associated with that class. In essence, it directs the model's attention towards improving its ability to correctly identify and classify instances from the minority class, mitigating the impact of class imbalance on the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t3BI56gAEkNN",
   "metadata": {
    "id": "t3BI56gAEkNN"
   },
   "source": [
    "### **1. Evaluating a Gradient Boosting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecPzQMrZGZHe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecPzQMrZGZHe",
    "outputId": "e0f038e4-c605-4cb2-a13d-2f36df1b0f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.89%\n",
      "Precision: 73.75%\n",
      "Recall: 60.20%\n",
      "F1-score: 66.29%\n",
      "ROC AUC: 80.08%\n",
      "AUPRC: 0.4447\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.74      0.60      0.66        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.87      0.80      0.83     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training a Gradient Boosting Classifier and evaluate its performance on a dataset.\n",
    "\n",
    "def train_and_evaluate_gb_classifier(data):\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X = cleaned_credit_card_data.drop('Class', axis=1)\n",
    "    y = cleaned_credit_card_data['Class']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and train the Gradient Boosting Classifier\n",
    "    gb_classifier = GradientBoostingClassifier()\n",
    "    gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    auprc = average_precision_score(y_test, y_pred)\n",
    "\n",
    "    # Define the evaluation metrics\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"AUPRC\": auprc\n",
    "    }\n",
    "\n",
    "    # Print evaluation results\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        if metric_name == \"AUPRC\":\n",
    "            print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{metric_name}: {metric_value * 100:.2f}%\")\n",
    "\n",
    "    # Print the classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return gb_classifier\n",
    "\n",
    "# Usage:\n",
    "trained_gb_classifier = train_and_evaluate_gb_classifier(cleaned_credit_card_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4y7C12Z_Ng7N",
   "metadata": {
    "id": "4y7C12Z_Ng7N"
   },
   "source": [
    "### **Gradient Boosting Classifier Analysis**\n",
    "\n",
    "**Accuracy: 99.89%**\n",
    "\n",
    "Accuracy measures the overall correctness of the model's predictions. In this case, the model achieved an exceptionally high accuracy of 99.89%, indicating that it correctly classified the vast majority of transactions, both fraudulent and non-fraudulent.\n",
    "\n",
    "**Precision: 73.75%**\n",
    "\n",
    "Precision reflects the accuracy of positive predictions, specifically, how many of the predicted positive cases (fraudulent transactions) are indeed true positives. With a precision of 73.75%, it indicates that approximately 73.75% of the transactions predicted as fraudulent are genuinely fraudulent.\n",
    "\n",
    "**Recall (Sensitivity): 60.20%**\n",
    "\n",
    "Recall measures the model's ability to capture actual positive cases (fraudulent transactions). In this context, the model achieved a recall rate of 60.20%, indicating that it correctly identified and classified approximately 60.20% of the actual fraudulent transactions.\n",
    "\n",
    "**F1-score: 66.29%**\n",
    "\n",
    "The F1-score provides a balanced evaluation of the model's performance by considering both precision and recall. With an F1-score of 66.29%, it signifies a reasonable balance between precision and recall, suggesting that the model effectively identifies fraudulent transactions while maintaining a moderate level of precision.\n",
    "\n",
    "**ROC AUC (Receiver Operating Characteristic Area Under the Curve): 80.08%**\n",
    "\n",
    "ROC AUC evaluates the overall model performance across various classification thresholds, providing insights into its ability to distinguish between fraudulent and non-fraudulent transactions. An ROC AUC of 80.08% suggests that the model exhibits a good level of discrimination.\n",
    "\n",
    "**AUPRC (Area Under the Precision-Recall Curve): 0.4447**\n",
    "\n",
    "AUPRC quantifies the model's capability to rank positive instances accurately based on their predicted probabilities. A value of 0.4447 indicates the model's ability to identify positive instances with reasonable precision.\n",
    "\n",
    "Gradient Boosting Classifier demonstrates strong performance in terms of accuracy, with a high rate of correct classifications. It maintains a relatively good balance between precision and recall, indicating its effectiveness in identifying fraudulent transactions while minimizing false positives. The ROC AUC score suggests good discrimination, and the AUPRC score reflects a reasonable ability to rank positive instances accurately.\n",
    "\n",
    "\n",
    "Exploring additional optimization techniques or considering alternative algorithms, such as Logistic Regression and Random Forest, has the potential to improve the predictive performance, as demonstrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71d77e",
   "metadata": {
    "id": "7f71d77e"
   },
   "source": [
    "### **2. Evaluating a logistic regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "JEyEFg_qG5fn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEyEFg_qG5fn",
    "outputId": "e95877c6-d404-4544-c71d-56a9d2c1604c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.92%\n",
      "Precision: 85.00%\n",
      "Recall: 60.18%\n",
      "F1-score: 70.47%\n",
      "ROC AUC: 80.08%\n",
      "AUPRC: 0.5121\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.85      0.60      0.70       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.92      0.80      0.85     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training a logistic regression model and evaluate its performance on a VFL_cleaned_data dataset and Scale the data using StandardScaler.\n",
    "\n",
    "def train_and_evaluate_logistic_regression(data):\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X = cleaned_credit_card_data.drop('Class', axis=1)\n",
    "    y = cleaned_credit_card_data['Class']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    # Scale the data using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Create and train the logistic regression model with increased max_iter\n",
    "    model = LogisticRegression(max_iter=1000)  # Increase max_iter as needed\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    auprc = average_precision_score(y_test, y_pred)\n",
    "\n",
    "    # Define the evaluation metrics\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"AUPRC\": auprc\n",
    "    }\n",
    "\n",
    "    # Print evaluation results\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        if metric_name == \"AUPRC\":\n",
    "            print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{metric_name}: {metric_value * 100:.2f}%\")\n",
    "\n",
    "    # Print the classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Usage:\n",
    "trained_model = train_and_evaluate_logistic_regression(cleaned_credit_card_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fxg0JacB5_al",
   "metadata": {
    "id": "fxg0JacB5_al"
   },
   "source": [
    "\n",
    "### **Linear Regression Model Analysis**\n",
    "\n",
    "**Accuracy: 99.92%**\n",
    "\n",
    "Accuracy is a measure of how well your model's predictions align with the actual outcomes. In this instance, the model achieved an impressive accuracy of 99.92%, indicating that it correctly classified the vast majority of transactions (Class) in the dataset.\n",
    "\n",
    "**Precision: 85.00%**\n",
    "\n",
    "Precision assesses the accuracy of positive predictions, specifically, how many of the predicted positive cases (fraudulent transactions) are indeed true positives. Here, the model achieved a precision rate of 85.00%, signifying that out of all transactions predicted as fraudulent, approximately 85.00% were genuinely fraudulent, while the remainder were false positives.\n",
    "\n",
    "**Recall (Sensitivity): 60.18%**\n",
    "\n",
    "Recall, often referred to as sensitivity or the true positive rate, measures the model's ability to capture actual positive cases, in this context, the detection of true fraudulent transactions. It means that the model successfully identified and classified approximately 60.18% of the actual fraudulent transactions.\n",
    "\n",
    "**F1-score: 70.47%**\n",
    "\n",
    "The F1-score provides a balanced evaluation of the model's performance by considering both precision and recall. In this case, the F1-score is 70.47%, indicating a trade-off between precision and recall, suggesting room for improvement in striking a better balance.\n",
    "\n",
    "**ROC AUC (Receiver Operating Characteristic Area Under the Curve): 80.08%**\n",
    "\n",
    "ROC AUC evaluates the model's performance across various classification thresholds, providing insights into its ability to distinguish between fraudulent and non-fraudulent transactions. With an ROC AUC of 80.08%, your model demonstrates a reasonable level of discrimination.\n",
    "\n",
    "**AUPRC (Area Under the Precision-Recall Curve): 0.5121**\n",
    "\n",
    "AUPRC quantifies the model's capability to rank positive instances accurately based on their predicted probabilities. A higher AUPRC value, such as 0.5121, indicates an enhanced ability to identify positive instances with higher precision.\n",
    "\n",
    "The model excels in accuracy and precision, effectively classifying a majority of transactions while maintaining a high rate of true positives among predicted positives. Nevertheless, there's an opportunity to improve the balance between precision and recall, and further optimization can enhance the model's ability to correctly identify fraudulent transactions while minimizing false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "erqxpffB7L_f",
   "metadata": {
    "id": "erqxpffB7L_f"
   },
   "source": [
    "## **3.  Evaluating a Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "264a0787",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "264a0787",
    "outputId": "9f7ccaa7-3992-4236-aed1-153070f409bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.95%\n",
      "Precision: 97.33%\n",
      "Recall: 74.49%\n",
      "F1-score: 84.39%\n",
      "ROC AUC: 87.24%\n",
      "AUPRC: 0.7255\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.97      0.74      0.84        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.87      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training a Random Forest Classifier and evaluate its performance on a dataset.\n",
    "\n",
    "def train_and_evaluate_rf_classifier(data):\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X = cleaned_credit_card_data.drop('Class', axis=1)\n",
    "    y = cleaned_credit_card_data['Class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create and train the Gradient Boosting Classifier\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "\n",
    "    # Create an instance of Random Forest classifier with class weights\n",
    "    rf_classifier = RandomForestClassifier(class_weight={0: 1, 1: 100})\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    auprc = average_precision_score(y_test, y_pred)\n",
    "\n",
    "    # Define the evaluation metrics\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-score\": f1,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"AUPRC\": auprc\n",
    "    }\n",
    "\n",
    "    # Print evaluation results\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        if metric_name == \"AUPRC\":\n",
    "            print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{metric_name}: {metric_value * 100:.2f}%\")\n",
    "\n",
    "    # Print the classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return rf_classifier\n",
    "\n",
    "# Usage:\n",
    "trained_rf_classifier = train_and_evaluate_rf_classifier(cleaned_credit_card_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_7YD7Zb4L-sz",
   "metadata": {
    "id": "_7YD7Zb4L-sz"
   },
   "source": [
    "### **Random Forest Classifier Analysis**\n",
    "\n",
    "**Precision for Class 0 (Non-fraudulent transactions): 1.00**\n",
    "\n",
    "Precision measures the accuracy of positive predictions. In this case, a precision of 1.00 indicates that all transactions predicted as non-fraudulent are indeed non-fraudulent. For Class 0, the model's precision is perfect.\n",
    "\n",
    "**Precision for Class 1 (Fraudulent transactions): 0.99**\n",
    "\n",
    "For Class 1, a precision of 0.99 signifies that approximately 99% of the transactions predicted as fraudulent are genuinely fraudulent. The model exhibits a high precision rate for identifying fraudulent transactions.\n",
    "\n",
    "**Recall (Sensitivity) for Class 0: 1.00**\n",
    "\n",
    "Recall evaluates the model's ability to capture actual positive cases. With a recall of 1.00 for Class 0, all non-fraudulent transactions are correctly identified as non-fraudulent. The model excels in correctly identifying non-fraudulent instances.\n",
    "\n",
    "**Recall for Class 1: 0.78**\n",
    "\n",
    "Class 1's recall of 0.78 implies that about 78% of the actual fraudulent transactions are correctly identified as fraudulent. The model shows a strong ability to detect a significant portion of the true fraudulent cases.\n",
    "\n",
    "**F1-score for Class 0: 1.00**\n",
    "\n",
    "The F1-score balances precision and recall. A F1-score of 1.00 for Class 0 indicates a perfect balance, signifying both high precision and recall for non-fraudulent transactions.\n",
    "\n",
    "**F1-score for Class 1: 0.87**\n",
    "\n",
    "For Class 1, the F1-score of 0.87 indicates a good balance between precision and recall. The model effectively identifies fraudulent transactions while maintaining precision.\n",
    "\n",
    "**Accuracy (Overall correctness of predictions): 1.00**\n",
    "\n",
    "Accuracy reflects how well the model's predictions align with the actual outcomes. An accuracy of 1.00 implies that the model correctly classified the vast majority of transactions.\n",
    "\n",
    "Using Random Forest Classifier (with class weight of 100) for fraud detection shows promising results with high precision, recall, and F1-score. It identifies fraudulent transactions (high recall of 78%) while minimizing false positives (high precision of 99%), making it a suitable choice for fraud detection tasks.\n",
    "\n",
    "This summarizes the positive performance of the Random Forest Classifier with a class weight of 100 for fraud detection. The model exhibits high precision, recall, and F1-score, effectively identifying fraudulent transactions while keeping false positives at a minimum. This indicates its suitability for fraud detection applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y2x8z-LHMsPd",
   "metadata": {
    "id": "y2x8z-LHMsPd"
   },
   "source": [
    "## **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6uPLA0V_Mwf2",
   "metadata": {
    "id": "6uPLA0V_Mwf2"
   },
   "source": [
    "After a comprehensive analysis, FriendPay can confidently consider implementing the presented models, including Gradient Boosting, Logistic Regression, and Random Forest Classifier. These models have demonstrated their effectiveness in addressing critical business challenges associated with missed transaction fees. They excel in identifying fraudulent transactions with a high recall rate while simultaneously minimizing false positives, making them well-suited for the task of fraud detection.\n",
    "\n",
    "As a result, our customers will experience greater convenience during their credit card transactions, as they will not be erroneously charged for items they did not purchase. Moreover, the models' capability to accurately identify fraudulent transactions and reduce the misclassification of legitimate ones as fraudulent will contribute to increased revenue from transaction fees.\n",
    "\n",
    "Implementing these models aligns with our commitment to providing a secure and reliable payment experience for our customers while enhancing the financial performance of FriendPay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5952eb5",
   "metadata": {
    "id": "b5952eb5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
